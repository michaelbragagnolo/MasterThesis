{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04c40761",
   "metadata": {},
   "source": [
    "***\n",
    "## Learning without Forgetting - LwF\n",
    "\n",
    "Experiment reproducing **Learning without Forgetting** method:  \n",
    "hybrid of Distillation Networks and fine-tuning, which refers to the re-training with a low learning rate an already trained model M with new and more specific dataset, D<sub>new</sub>, with respect to the dataset, D<sub>old</sub>, with which the given model M was originally trained.\n",
    "\n",
    "LwF, as opposed to other continual learning techniques, only uses the new data, so it assumes that past data used to pre-train the network is unavailable.  \n",
    "It is a *transfer learning technique*.\n",
    "\n",
    "`References:`\n",
    "- Learning without Forgetting: https://arxiv.org/abs/1606.09282\n",
    "- Three scenarios for continual learning: https://arxiv.org/abs/1904.07734"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2df4d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing framework and test runner\n",
    "import unittest\n",
    "\n",
    "# Avalanche library\n",
    "import avalanche as avl\n",
    "from avalanche.evaluation import metrics as metrics\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "# Avalanche NN model\n",
    "from models import MLP\n",
    "\n",
    "from utils import create_default_args, get_average_metric, get_target_result\n",
    "\n",
    "\n",
    "class LwF(unittest.TestCase): #TestCase class\n",
    "\n",
    "    ## ------- Split MNIST benchmark ------- ##\n",
    "    def test_smnist(self, override_args=None):\n",
    "        \n",
    "        args = create_default_args({'cuda': 0,              #\n",
    "                                    'lwf_alpha': 1,         #\n",
    "                                    'lwf_temperature': 1,   #\n",
    "                                    'epochs': 10,           #\n",
    "                                    'layers': 1,            #\n",
    "                                    'hidden_size': 256,     #\n",
    "                                    'learning_rate': 0.001, #\n",
    "                                    'train_mb_size': 128}, override_args) #\n",
    "\n",
    "        # Set up and run CUDA operations.\n",
    "        # if CUDA is available, utilize GPUs for computation.\n",
    "        device = torch.device(f\"cuda:{args.cuda}\"\n",
    "                              if torch.cuda.is_available() and args.cuda >= 0 \n",
    "                              else \"cpu\")\n",
    "        \n",
    "        # Define the benchmark:\n",
    "        # stream composed of 5 experiences from SplitMNIST dataset\n",
    "        benchmark = avl.benchmarks.SplitMNIST(5, return_task_id=False)\n",
    "        \n",
    "        # NN model and loss function\n",
    "        model = MLP(hidden_size=args.hidden_size, hidden_layers=args.layers)\n",
    "        criterion = CrossEntropyLoss()\n",
    "\n",
    "        # Avalanche logging module, displays a progress bar during training and evaluation\n",
    "        interactive_logger = avl.logging.InteractiveLogger()\n",
    "        \n",
    "        # Metrics of main interest to be evaluated\n",
    "        evaluation_plugin = avl.training.plugins.EvaluationPlugin(\n",
    "            metrics.accuracy_metrics(epoch=True, experience=True, stream=True),\n",
    "            loggers=[interactive_logger], benchmark=benchmark)\n",
    "\n",
    "        # Define the Continual Learning strategy LwF with the previously assigned parameters\n",
    "        cl_strategy = avl.training.LwF(\n",
    "            model, SGD(model.parameters(), lr=args.learning_rate), criterion,\n",
    "            alpha=args.lwf_alpha, temperature=args.lwf_temperature,\n",
    "            train_mb_size=args.train_mb_size, train_epochs=args.epochs,\n",
    "            device=device, evaluator=evaluation_plugin)\n",
    "\n",
    "        for experience in benchmark.train_stream:\n",
    "            cl_strategy.train(experience)\n",
    "            res = cl_strategy.eval(benchmark.test_stream)\n",
    "\n",
    "        avg_stream_acc = get_average_metric(res)\n",
    "        print(f\"LwF-SMNIST Average Stream Accuracy: {avg_stream_acc:.2f}\")\n",
    "\n",
    "        target_acc = float(get_target_result('lwf', 'smnist'))\n",
    "        if args.check:\n",
    "            self.assertAlmostEqual(target_acc, avg_stream_acc, delta=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0640d573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
