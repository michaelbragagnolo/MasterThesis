{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0e7ab0",
   "metadata": {},
   "source": [
    "# Avalanche tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52631c2b",
   "metadata": {},
   "source": [
    "**experience** = Set composed of one or multiple samples which can be used to update the model (oftern referred as batch or task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c40761",
   "metadata": {},
   "source": [
    "***\n",
    "## Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04c0fd0",
   "metadata": {},
   "source": [
    "Every continual learning algorithm needs a model to train incrementally.\n",
    "\n",
    "The `models` sub-module provides for you the most commonly used architectures in the CL literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a08297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.models import SimpleCNN\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.models import SimpleMLP_TinyImageNet\n",
    "from avalanche.models import MobilenetV1\n",
    "\n",
    "model = SimpleCNN()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c6b15",
   "metadata": {},
   "source": [
    "A continual learning model may change over time. As an example, a classifier may add new units for previously unseen classes, while progressive networks add a new set units after each experience. Avalanche provides `DynamicModules` to support these use cases. \n",
    "\n",
    "`DynamicModules` are torch.nn.Modules that provide an addition method, adaptation, that is used to update the model's architecture. The method takes a single argument, the data from the current experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47b0be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import benchmark\n",
    "from avalanche.benchmarks import SplitMNIST\n",
    "\n",
    "# Import model\n",
    "from avalanche.models import IncrementalClassifier\n",
    "\n",
    "# Stream composed of 5 experiences from SplitMNIST dataset\n",
    "benchmark = SplitMNIST(n_experiences=5, shuffle=False)\n",
    "\n",
    "model = IncrementalClassifier(in_features=784)\n",
    "print(model)\n",
    "\n",
    "for exp in benchmark.train_stream:\n",
    "    model.adaptation(exp.dataset)\n",
    "    # After each call to the adaption method, the model adds 2 new units to account for new classes.\n",
    "    # NO learning occurs at this point, the method only modifies the model's architecture.\n",
    "    print(model)\n",
    "    \n",
    "# When you use Avalanche strategies you don't have to call the adaptation yourself. \n",
    "# Avalanche strategies automatically call the model's adaptation and update the optimizer to include new parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f12a37",
   "metadata": {},
   "source": [
    "***\n",
    "## Benchmarks\n",
    "The `benchmark` module generates the data stream that the targeted system, powered by a CL strategy, is required to learn from experiences in order to improve its performance or expand its set of capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45d2947",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "Collection of examples that can be used for training or testing purposes, not already organized to be processed as a stream of batches or tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5e6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Import datasets\n",
    "from avalanche.benchmarks.datasets import MNIST\n",
    "\n",
    "#-- Create train and test sets from the imported datasets --#\n",
    "\n",
    "# Create TRAIN set from MNIST dataset\n",
    "train_MNIST = MNIST('./data/mnist', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# Create TEST  set from MNIST dataset\n",
    "test_MNIST  = MNIST('./data/mnist', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# Iterate on the generated set to get the examples one by one\n",
    "for i, example in enumerate(train_MNIST):\n",
    "    pass\n",
    "print(\"Num. examples processed: {}\".format(i))\n",
    "\n",
    "# or use a Pytorch DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_MNIST, batch_size=32, shuffle=True)\n",
    "for i, (x, y) in enumerate(train_loader):\n",
    "    pass\n",
    "print(\"Num. mini-batch processed: {}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7856518",
   "metadata": {},
   "source": [
    "### Benchmarks basics\n",
    "The Avalanche benchmarks (instances of the Scenario class), contains several attributes that characterize the benchmark. However, the most important ones are the train and test streams.\n",
    "\n",
    "In Avalanche we often suppose to have access to these two parallel stream of data (even though some benchmarks may not provide such feature, but contain just a unique test set).\n",
    "\n",
    "Each of these streams are iterable, indexable and sliceable objects that are composed of unique experiences. Experiences are batch of data (or \"tasks\") that can be provided with or without a specific task label.\n",
    "\n",
    "`Efficiency`: All the data belonging to a stream are not loaded into the RAM beforehand. Avalanche actually loads the data when a specific mini-batches are requested at training/test time based on the policy defined by each Dataset implementation. This means that memory requirements are very low, while the speed is guaranteed by a multi-processing data loading system based on the one defined in Pytorch.\n",
    "\n",
    "`Scenarios`: Particular setting, specificities about the continual stream of data, a continual learning algorithm will face; each scenario object in Avalanche has several useful attributes that characterizes the benchmark, including the two important train and test streams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41811c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks.classic import SplitMNIST\n",
    "\n",
    "split_mnist = SplitMNIST(n_experiences=5, seed=1) #seed is the starting point for the sequence\n",
    "\n",
    "# Original train/test sets\n",
    "print('--- Original datasets:')\n",
    "print(split_mnist.original_train_dataset)\n",
    "print(split_mnist.original_test_dataset)\n",
    "\n",
    "# A list describing which training patterns are assigned to each experience.\n",
    "# Patterns are identified by their id w.r.t. the dataset found in the\n",
    "# original_train_dataset field.\n",
    "print('--- Train patterns assignment:')\n",
    "print(split_mnist.train_exps_patterns_assignment)\n",
    "\n",
    "# A list describing which test patterns are assigned to each experience.\n",
    "# Patterns are identified by their id w.r.t. the dataset found in the\n",
    "# original_test_dataset field\n",
    "print('--- Test patterns assignment:')\n",
    "print(split_mnist.test_exps_patterns_assignment)\n",
    "\n",
    "# the task label of each experience.\n",
    "print('--- Task labels:')\n",
    "print(split_mnist.task_labels)\n",
    "\n",
    "# train and test streams\n",
    "print('--- Streams:')\n",
    "print(split_mnist.train_stream)\n",
    "print(split_mnist.test_stream)\n",
    "\n",
    "# A list that, for each experience (identified by its index/ID),\n",
    "# stores a set of the (optionally remapped) IDs of classes of patterns\n",
    "# assigned to that experience.\n",
    "print('--- Classes in each experience:')\n",
    "split_mnist.classes_in_experience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6824191",
   "metadata": {},
   "source": [
    "#### Train and Test streams\n",
    "The train and test streams can be used for training and testing purposes, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a844d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each stream has a name: \"train\" or \"test\"\n",
    "train_stream = split_mnist.train_stream\n",
    "print(train_stream.name)\n",
    "\n",
    "# we have access to the scenario from which the stream was taken\n",
    "train_stream.benchmark\n",
    "\n",
    "# we can slice and reorder the stream as we like!\n",
    "substream = train_stream[0]\n",
    "substream = train_stream[0:2]\n",
    "substream = train_stream[0,2,1]\n",
    "\n",
    "len(substream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c8052",
   "metadata": {},
   "source": [
    "#### Experiences\n",
    "Each stream can in turn be treated as an iterator that produces a unique experience, containing all the useful data regarding a batch or task in the continual stream our algorithms will face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get the first experience\n",
    "experience = train_stream[0]\n",
    "\n",
    "# task label and dataset are the main attributes\n",
    "t_label = experience.task_label\n",
    "dataset = experience.dataset\n",
    "\n",
    "# but you can recover additional info\n",
    "experience.current_experience\n",
    "experience.classes_in_this_experience\n",
    "experience.classes_seen_so_far\n",
    "experience.previous_classes\n",
    "experience.future_classes\n",
    "experience.origin_stream\n",
    "experience.benchmark\n",
    "\n",
    "# As always, we can iterate over it normally or with a pytorch data loader.\n",
    "# For instance, we can use tqdm to add a progress bar.\n",
    "from tqdm import tqdm\n",
    "for i, data in enumerate(tqdm(dataset)):\n",
    "  pass\n",
    "\n",
    "print(\"\\nNumber of examples:\", i + 1)\n",
    "print(\"Task Label:\", t_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124dbf08",
   "metadata": {},
   "source": [
    "### Classic Benchmarks\n",
    "Now that we know how our benchmarks work in general through scenarios, streams and experiences objects, in this section we are going to explore common benchmarks already available for you with one line of code yet flexible enough to allow proper tuning based on your needs.\n",
    "\n",
    "Many of the classic benchmarks will download the original datasets they are based on automatically and put it under the \"~/.avalanche/data\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ebfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks.classic import CORe50, SplitTinyImageNet,   \\\n",
    "SplitCIFAR10, SplitCIFAR100, SplitCIFAR110, SplitMNIST, RotatedMNIST, \\\n",
    "PermutedMNIST, SplitCUB200, SplitImageNet\n",
    "\n",
    "# creating PermutedMNIST (Task-Incremental)\n",
    "perm_mnist = PermutedMNIST(n_experiences=2,seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8793005",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Test of the classic PermutedMNIST benchmark -- ##\n",
    "\n",
    "# creating the benchmark instance (scenario object)\n",
    "perm_mnist = PermutedMNIST(n_experiences=3, seed=1234)\n",
    "\n",
    "# recovering the train and test streams\n",
    "train_stream = perm_mnist.train_stream\n",
    "test_stream  = perm_mnist.test_stream\n",
    "\n",
    "# iterating over the train stream\n",
    "for experience in train_stream:\n",
    "  print(\"Start of task \", experience.task_label)\n",
    "  print('Classes in this task:', experience.classes_in_this_experience)\n",
    "\n",
    "  # The current Pytorch training set can be easily recovered through the experience\n",
    "  current_training_set = experience.dataset\n",
    "  # ...as well as the task_label\n",
    "  print('Task {}'.format(experience.task_label))\n",
    "  print('This task contains', len(current_training_set), 'training examples')\n",
    "\n",
    "  # we can recover the corresponding test experience in the test stream\n",
    "  current_test_set = test_stream[experience.current_experience].dataset\n",
    "  print('This task contains', len(current_test_set), 'test examples')\n",
    "  print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
